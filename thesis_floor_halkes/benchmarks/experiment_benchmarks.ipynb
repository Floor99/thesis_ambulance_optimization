{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f019d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from thesis_floor_halkes.features.dynamic.getter import DynamicFeatureGetterDataFrame\n",
    "from thesis_floor_halkes.features.graph.graph_generator import create_osmnx_sub_graph_only_inside_helmond, get_edge_features_subgraph, get_node_features_subgraph, plot_sub_graph_in_and_out_nodes_helmond\n",
    "from thesis_floor_halkes.features.static.new_getter import get_static_data_object_subgraph\n",
    "from thesis_floor_halkes.utils.adj_matrix import build_adjecency_matrix\n",
    "from thesis_floor_halkes.utils.haversine import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df8baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis_floor_halkes.benchmarks.time_dependent_A_star import time_dependent_a_star\n",
    "from thesis_floor_halkes.benchmarks.time_dependent_dijkstra import time_dependent_dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d272cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data = torch.load('/home/floor/projects/FINAL/thesis_ambulance_optimization/data/training_data/network_0/network_0_29_15.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0232fbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[178, 4], edge_index=[2, 526], edge_attr=[526, 2], start_node=29, end_node=15, G_sub=MultiDiGraph with 178 nodes and 526 edges, G_pt=MultiDiGraph with 178 nodes and 566 edges, timeseries=        node_id osmid_original tlc_name        lat       lon  has_light  \\\n",
       "0             0     [42728835]        0  51.475534  5.678364          0   \n",
       "1             0     [42728835]        0  51.475534  5.678364          0   \n",
       "2             0     [42728835]        0  51.475534  5.678364          0   \n",
       "3             0     [42728835]        0  51.475534  5.678364          0   \n",
       "4             0     [42728835]        0  51.475534  5.678364          0   \n",
       "...         ...            ...      ...        ...       ...        ...   \n",
       "256315      177     [42762652]        0  51.486164  5.670416          0   \n",
       "256316      177     [42762652]        0  51.486164  5.670416          0   \n",
       "256317      177     [42762652]        0  51.486164  5.670416          0   \n",
       "256318      177     [42762652]        0  51.486164  5.670416          0   \n",
       "256319      177     [42762652]        0  51.486164  5.670416          0   \n",
       "\n",
       "        distance_m           timestamp  wait_time  start_node  end_node  \\\n",
       "0       104.357170 2024-01-31 00:00:00   8.745401          29        15   \n",
       "1       104.357170 2024-01-31 00:01:00   6.144555          29        15   \n",
       "2       104.357170 2024-01-31 00:02:00   6.744262          29        15   \n",
       "3       104.357170 2024-01-31 00:03:00   7.352014          29        15   \n",
       "4       104.357170 2024-01-31 00:04:00   7.745347          29        15   \n",
       "...            ...                 ...        ...         ...       ...   \n",
       "256315  321.353179 2024-01-31 23:55:00  14.756711          29        15   \n",
       "256316  321.353179 2024-01-31 23:56:00  14.756711          29        15   \n",
       "256317  321.353179 2024-01-31 23:57:00  14.756711          29        15   \n",
       "256318  321.353179 2024-01-31 23:58:00  14.756711          29        15   \n",
       "256319  321.353179 2024-01-31 23:59:00  14.756711          29        15   \n",
       "\n",
       "        distance_to_goal_meters  \n",
       "0                    487.831984  \n",
       "1                    487.831984  \n",
       "2                    487.831984  \n",
       "3                    487.831984  \n",
       "4                    487.831984  \n",
       "...                         ...  \n",
       "256315              1101.581644  \n",
       "256316              1101.581644  \n",
       "256317              1101.581644  \n",
       "256318              1101.581644  \n",
       "256319              1101.581644  \n",
       "\n",
       "[256320 rows x 12 columns])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0ddfaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_node_idx = {\n",
    "    \"status\": 0,\n",
    "    \"wait_time\": 1,\n",
    "    \"current_node\": 2,\n",
    "    \"visited_nodes\": 3,\n",
    "}\n",
    "\n",
    "static_node_idx = {\n",
    "    \"lat\": 0,\n",
    "    \"lon\": 1,\n",
    "    \"has_light\": 2,\n",
    "    \"dist_to_goal\": 3,\n",
    "}\n",
    "\n",
    "static_edge_idx = {\n",
    "    \"length\": 0,\n",
    "    \"speed\": 1,\n",
    "}\n",
    "\n",
    "dynamic_feature_getter = DynamicFeatureGetterDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87b75300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_dependent_dijkstra(\n",
    "    static_data, \n",
    "    dynamic_feature_getter, \n",
    "    dynamic_node_idx,\n",
    "    static_node_idx,\n",
    "    static_edge_idx,\n",
    "):\n",
    "    df = static_data.timeseries.copy()\n",
    "    start_node = static_data.start_node\n",
    "    \n",
    "    df_start = df[df['node_id'] == start_node]\n",
    "    time_stamps = sorted(df_start[\"timestamp\"].unique())\n",
    "    ts0 = pd.to_datetime(time_stamps[0])  # ensures it's a pandas.Timestamp\n",
    "    t0 = time_stamps.index(ts0) # index of the first timestamp\n",
    "    \n",
    "    T = len(time_stamps)\n",
    "    \n",
    "    adj = build_adjecency_matrix(static_data.num_nodes, static_data)\n",
    "    start = static_data.start_node\n",
    "    end = static_data.end_node\n",
    "    \n",
    "    class _TmpEnv:\n",
    "        pass \n",
    "    tmp = _TmpEnv()\n",
    "    tmp.static_data = static_data\n",
    "    tmp.static_node_idx = static_node_idx\n",
    "    \n",
    "    heap = [(0.0, start, t0, [start])]\n",
    "    best = {(start, t0): 0.0}\n",
    "    \n",
    "    while heap: \n",
    "        cost, node, t_idx, path = heapq.heappop(heap)\n",
    "        # print(f\"[POP] cost={cost:.3f}, node={node}, t_idx={t_idx}, path={path}\")\n",
    "        if cost > best.get((node, t_idx), float(\"inf\")):\n",
    "            # print(\"       → skipping stale entry\")\n",
    "            continue\n",
    "        if node == end:\n",
    "            # print(f\"[FOUND] cost={cost:.3f}, path={path}\")\n",
    "            return cost, path\n",
    "        next_t = t_idx + 1\n",
    "        if next_t >= T:\n",
    "            # print(f\"       → next_t={next_t} ≥ T={T}, no further expansion\")\n",
    "            continue\n",
    "        # print(f\"       → expanding at time index {next_t} (ts={time_stamps[next_t]})\")\n",
    "    \n",
    "        dyn = dynamic_feature_getter.get_dynamic_features(\n",
    "            environment = tmp, \n",
    "            traffic_light_idx = static_node_idx[\"has_light\"],\n",
    "            current_node = node, \n",
    "            visited_nodes = path,\n",
    "            time_step = next_t, \n",
    "            sub_node_df = df,\n",
    "        )\n",
    "        wait_times = dyn.x[:, dynamic_node_idx[\"wait_time\"]]\n",
    "        \n",
    "        for nbr, eidx in adj[node]:\n",
    "            length = static_data.edge_attr[eidx, static_edge_idx[\"length\"]]\n",
    "            speed = static_data.edge_attr[eidx, static_edge_idx[\"speed\"]]\n",
    "            travel_time = length / (speed / 3.6)\n",
    "            light_status = dyn.x[nbr, dynamic_node_idx[\"status\"]].item()\n",
    "            if light_status == 1:  # green light\n",
    "                wait = 0.0\n",
    "            else:  # red light\n",
    "                wait = wait_times[nbr].item()\n",
    "            \n",
    "            ts = time_stamps[next_t]\n",
    "            orig_wait_series = df[\n",
    "                (df[\"node_id\"] == nbr) & (df[\"timestamp\"] == ts)\n",
    "            ]\n",
    "            # print(f\"  Original wait series:\\n {orig_wait_series}\\n\")\n",
    "            # print(f\"node = {nbr} @ ts={ts}\"\n",
    "            #       f\"> dyn.get() = {wait:.2f}s \")\n",
    "            \n",
    "            \n",
    "            new_cost = cost + travel_time + wait\n",
    "            \n",
    "            # print(\n",
    "            #         f\"         edge {node}→{nbr}: travel={travel_time:.2f}, \"\n",
    "            #         f\"wait={wait:.2f} → new_cost={new_cost:.2f}\"\n",
    "            #     )\n",
    "            \n",
    "            key = (nbr, next_t)\n",
    "            if new_cost < best.get(key, float(\"inf\")):\n",
    "                best[key] = new_cost\n",
    "                heapq.heappush(heap, (new_cost, nbr, next_t, path + [nbr]))\n",
    "                # print(f\"           • pushed (cost={new_cost:.2f}, node={nbr}, t={next_t})\")\n",
    "        \n",
    "    return None, float(\"inf\")  # No path found\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c11a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dijkstra_on_dataset(split_name, base_dir):\n",
    "    print(f\"\\nRunning Time-Dependent Dijkstra on {split_name.upper()} set\")\n",
    "    results = []\n",
    "\n",
    "    network_dirs = sorted([\n",
    "        os.path.join(base_dir, d)\n",
    "        for d in os.listdir(base_dir)\n",
    "        if os.path.isdir(os.path.join(base_dir, d))\n",
    "    ])\n",
    "\n",
    "    for network_dir in network_dirs:\n",
    "        pt_files = glob(os.path.join(network_dir, \"*.pt\"))\n",
    "        print(f\"Found {len(pt_files)} graphs in {network_dir}\")\n",
    "\n",
    "        for pt_file in pt_files:\n",
    "            try:\n",
    "                static_data = torch.load(pt_file, weights_only=False)\n",
    "\n",
    "                dynamic_feature_getter = DynamicFeatureGetterDataFrame()\n",
    "\n",
    "                start = time.time()\n",
    "                cost, route = time_dependent_dijkstra(\n",
    "                    static_data,\n",
    "                    dynamic_feature_getter,\n",
    "                    dynamic_node_idx,\n",
    "                    static_node_idx,\n",
    "                    static_edge_idx,\n",
    "                )\n",
    "                end = time.time()\n",
    "\n",
    "                results.append({\n",
    "                    \"file\": pt_file,\n",
    "                    \"network\": f\"{os.path.basename(network_dir)}_{static_data.start_node}_{static_data.end_node}\",\n",
    "                    \"success\": cost is not None,\n",
    "                    \"cost\": cost.item() if cost is not None else float(\"inf\"),\n",
    "                    \"route\": route,\n",
    "                    \"route_len\": len(route),\n",
    "                    \"runtime_s\": end - start,\n",
    "                    \"split\": split_name\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error in file {pt_file}: {e}\")\n",
    "                results.append({\n",
    "                    \"file\": pt_file,\n",
    "                    \"network\": os.path.basename(network_dir),\n",
    "                    \"success\": False,\n",
    "                    \"cost\": float(\"inf\"),\n",
    "                    \"route_len\": 0,\n",
    "                    \"runtime_s\": 0.0,\n",
    "                    \"split\": split_name\n",
    "                })\n",
    "        break\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd45f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Time-Dependent Dijkstra on TRAIN set\n",
      "Found 4 graphs in /home/floor/projects/FINAL/thesis_ambulance_optimization/data/training_data/network_0\n"
     ]
    }
   ],
   "source": [
    "df = run_dijkstra_on_dataset(\"train\", \"/home/floor/projects/FINAL/thesis_ambulance_optimization/data/training_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12f3a845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>network</th>\n",
       "      <th>success</th>\n",
       "      <th>cost</th>\n",
       "      <th>route</th>\n",
       "      <th>route_len</th>\n",
       "      <th>runtime_s</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/floor/projects/FINAL/thesis_ambulance_op...</td>\n",
       "      <td>network_0_51_15</td>\n",
       "      <td>True</td>\n",
       "      <td>200.515228</td>\n",
       "      <td>[51, 73, 64, 59, 49, 40, 30, 38, 16, 14, 15]</td>\n",
       "      <td>11</td>\n",
       "      <td>14.358259</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/floor/projects/FINAL/thesis_ambulance_op...</td>\n",
       "      <td>network_0_29_15</td>\n",
       "      <td>True</td>\n",
       "      <td>186.441376</td>\n",
       "      <td>[29, 28, 22, 17, 19, 20, 30, 38, 16, 14, 15]</td>\n",
       "      <td>11</td>\n",
       "      <td>11.472449</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/floor/projects/FINAL/thesis_ambulance_op...</td>\n",
       "      <td>network_0_137_167</td>\n",
       "      <td>True</td>\n",
       "      <td>71.614182</td>\n",
       "      <td>[137, 143, 157, 150, 167]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.562073</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/floor/projects/FINAL/thesis_ambulance_op...</td>\n",
       "      <td>network_0_107_47</td>\n",
       "      <td>True</td>\n",
       "      <td>244.224152</td>\n",
       "      <td>[107, 105, 103, 51, 73, 64, 59, 49, 40, 56, 65...</td>\n",
       "      <td>12</td>\n",
       "      <td>18.279907</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file            network  \\\n",
       "0  /home/floor/projects/FINAL/thesis_ambulance_op...    network_0_51_15   \n",
       "1  /home/floor/projects/FINAL/thesis_ambulance_op...    network_0_29_15   \n",
       "2  /home/floor/projects/FINAL/thesis_ambulance_op...  network_0_137_167   \n",
       "3  /home/floor/projects/FINAL/thesis_ambulance_op...   network_0_107_47   \n",
       "\n",
       "   success        cost                                              route  \\\n",
       "0     True  200.515228       [51, 73, 64, 59, 49, 40, 30, 38, 16, 14, 15]   \n",
       "1     True  186.441376       [29, 28, 22, 17, 19, 20, 30, 38, 16, 14, 15]   \n",
       "2     True   71.614182                          [137, 143, 157, 150, 167]   \n",
       "3     True  244.224152  [107, 105, 103, 51, 73, 64, 59, 49, 40, 56, 65...   \n",
       "\n",
       "   route_len  runtime_s  split  \n",
       "0         11  14.358259  train  \n",
       "1         11  11.472449  train  \n",
       "2          5   0.562073  train  \n",
       "3         12  18.279907  train  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8810578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_success_travel_time_score(df, alpha, beta, min_time=0, max_time=1000):\n",
    "    \"\"\"\n",
    "    Calculate a normalized score from individual route success and travel times.\n",
    "    \n",
    "    - `alpha`: weight for success rate\n",
    "    - `beta`: weight for normalized penalized travel time\n",
    "    - `min_time`, `max_time`: used to normalize travel times\n",
    "    \"\"\"\n",
    "    # Extract per-sample success (1.0/0.0) and travel time\n",
    "    success_rates = df['success'].astype(float).tolist()\n",
    "    travel_times = df['cost'].tolist()\n",
    "\n",
    "    # Min-max normalize travel times\n",
    "    penalized_travel_times = np.array(travel_times)\n",
    "    penalized_travel_times = (penalized_travel_times - min_time) / (max_time - min_time)\n",
    "    penalized_travel_times = np.clip(penalized_travel_times, 0, 1)\n",
    "\n",
    "    # Compute final score\n",
    "    score = (\n",
    "        alpha * np.mean(success_rates)\n",
    "        - beta * np.mean(penalized_travel_times)\n",
    "    )\n",
    "    \n",
    "    return score.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c04cb50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7648602531433106"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_success_travel_time_score(df, alpha=0.8, beta=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964be219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_dependent_a_star(\n",
    "    static_data,\n",
    "    dynamic_feature_getter,\n",
    "    dynamic_node_idx,\n",
    "    static_node_idx,\n",
    "    static_edge_idx,\n",
    "):\n",
    "    df = static_data.timeseries.copy()\n",
    "    start_node = static_data.start_node\n",
    "    end_node = static_data.end_node\n",
    "    # print(f\"Start node: {start_node}\")\n",
    "    # print(f\"End node: {end_node}\")\n",
    "\n",
    "    df_start = df[df['node_id'] == start_node]\n",
    "    time_stamps = sorted(df_start[\"timestamp\"].unique())\n",
    "    ts0 = pd.to_datetime(time_stamps[0])  # ensures it's a pandas.Timestamp\n",
    "    t0 = time_stamps.index(ts0) # index of the first timestamp\n",
    "    \n",
    "    T = len(time_stamps)\n",
    "\n",
    "    adj = build_adjecency_matrix(static_data.num_nodes, static_data)\n",
    "\n",
    "    # Heuristic: straight-line distance to goal / max speed (in seconds)\n",
    "    max_speed = static_data.edge_attr[:, static_edge_idx['speed']].max().item()\n",
    "    dist_to_goal = static_data.x[:, static_node_idx['dist_to_goal']]  # meters\n",
    "\n",
    "    def heuristic(node):\n",
    "        # max_speed in km/h, convert to m/s\n",
    "        return dist_to_goal[node].item() / (max_speed / 3.6 + 1e-6)\n",
    "\n",
    "    class _TmpEnv:\n",
    "        pass\n",
    "    tmp = _TmpEnv()\n",
    "    tmp.static_data = static_data\n",
    "    tmp.static_node_idx = static_node_idx\n",
    "\n",
    "    heap = [(heuristic(start_node), 0.0, start_node, t0, [start_node])]\n",
    "    best = {(start_node, t0): 0.0}\n",
    "\n",
    "    while heap:\n",
    "        est_total, cost, node, t_idx, path = heapq.heappop(heap)\n",
    "        if cost > best.get((node, t_idx), float(\"inf\")):\n",
    "            continue\n",
    "        if node == end_node:\n",
    "            # print(f\"[FOUND] cost={cost:.3f}, path={path}\")\n",
    "            return cost, path\n",
    "        next_t = t_idx + 1\n",
    "        if next_t >= T:\n",
    "            continue\n",
    "\n",
    "        dyn = dynamic_feature_getter.get_dynamic_features(\n",
    "            environment=tmp,\n",
    "            traffic_light_idx=static_node_idx[\"has_light\"],\n",
    "            current_node=node,\n",
    "            visited_nodes=path,\n",
    "            time_step=next_t,\n",
    "            sub_node_df=df,\n",
    "        )\n",
    "        wait_times = dyn.x[:, dynamic_node_idx[\"wait_time\"]]\n",
    "\n",
    "        for nbr, eidx in adj[node]:\n",
    "            length = static_data.edge_attr[eidx, static_edge_idx[\"length\"]]\n",
    "            speed = static_data.edge_attr[eidx, static_edge_idx[\"speed\"]]\n",
    "            travel_time = length / (speed / 3.6)\n",
    "            \n",
    "            light_status = dyn.x[nbr, dynamic_node_idx[\"status\"]].item()\n",
    "            if light_status == 1:  # green light\n",
    "                wait = 0.0\n",
    "            else:  # red light\n",
    "                wait = wait_times[nbr].item()\n",
    "            \n",
    "            new_cost = cost + travel_time + wait\n",
    "            key = (nbr, next_t)\n",
    "            \n",
    "            if new_cost < best.get(key, float(\"inf\")):\n",
    "                best[key] = new_cost\n",
    "                est = new_cost + heuristic(nbr)\n",
    "                heapq.heappush(heap, (est, new_cost, nbr, next_t, path + [nbr]))\n",
    "\n",
    "    return None, float(\"inf\")  # No path found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "468919d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start node: 29\n",
      "End node: 15\n",
      "[FOUND] cost=186.441, path=[29, 28, 22, 17, 19, 20, 30, 38, 16, 14, 15]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(186.4414), [29, 28, 22, 17, 19, 20, 30, 38, 16, 14, 15])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_dependent_a_star(static_data,dynamic_feature_getter, dynamic_node_idx, static_node_idx, static_edge_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_dataset(split_name, base_dir, routing_fn):\n",
    "    \"\"\"\n",
    "    Run a given routing function (e.g. time_dependent_dijkstra or a_star) \n",
    "    on all .pt graph files in the specified split directory.\n",
    "    \n",
    "    Parameters:\n",
    "        split_name (str): \"train\", \"val\", or \"test\"\n",
    "        base_dir (str): base directory for the split (e.g. \"training_data\")\n",
    "        routing_fn (function): the routing function to apply to each graph\n",
    "    \"\"\"\n",
    "    print(f\"\\nRunning {routing_fn.__name__} on {split_name.upper()} set\")\n",
    "    results = []\n",
    "\n",
    "    network_dirs = sorted([\n",
    "        os.path.join(base_dir, d)\n",
    "        for d in os.listdir(base_dir)\n",
    "        if os.path.isdir(os.path.join(base_dir, d))\n",
    "    ])\n",
    "\n",
    "    for network_dir in network_dirs:\n",
    "        pt_files = glob(os.path.join(network_dir, \"*.pt\"))\n",
    "        print(f\"Found {len(pt_files)} graphs in {network_dir}\")\n",
    "\n",
    "        for pt_file in pt_files:\n",
    "            try:\n",
    "                static_data = torch.load(pt_file, weights_only=False)\n",
    "                dynamic_feature_getter = DynamicFeatureGetterDataFrame()\n",
    "\n",
    "                start = time.time()\n",
    "                cost, route = routing_fn(\n",
    "                    static_data,\n",
    "                    dynamic_feature_getter,\n",
    "                    dynamic_node_idx,\n",
    "                    static_node_idx,\n",
    "                    static_edge_idx,\n",
    "                )\n",
    "                end = time.time()\n",
    "\n",
    "                results.append({\n",
    "                    \"file\": pt_file,\n",
    "                    \"network\": os.path.basename(network_dir),\n",
    "                    \"success\": cost is not None,\n",
    "                    \"cost\": cost.item() if cost is not None else float(\"inf\"),\n",
    "                    \"route\": route,\n",
    "                    \"route_len\": len(route),\n",
    "                    \"runtime_s\": end - start,\n",
    "                    \"split\": split_name,\n",
    "                    \"algorithm\": routing_fn.__name__\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error in file {pt_file}: {e}\")\n",
    "                results.append({\n",
    "                    \"file\": pt_file,\n",
    "                    \"network\": os.path.basename(network_dir),\n",
    "                    \"success\": False,\n",
    "                    \"cost\": float(\"inf\"),\n",
    "                    \"route_len\": 0,\n",
    "                    \"runtime_s\": 0.0,\n",
    "                    \"split\": split_name,\n",
    "                    \"algorithm\": routing_fn.__name__\n",
    "                })\n",
    "        break  # Only process the first network for now\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72211919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_evaluations(base_dirs, output_root, algorithms):\n",
    "    \"\"\"\n",
    "    Runs each algorithm on each dataset split and saves the results.\n",
    "    \n",
    "    Parameters:\n",
    "        base_dirs (dict): {split_name: path_to_split}\n",
    "                          e.g., {\"train\": \"training_data\", \"val\": \"val_data\", \"test\": \"test_data\"}\n",
    "        output_root (str): Base output directory (results will go into subfolders here)\n",
    "        algorithms (dict): {name: function} — e.g., {\"dijkstra\": time_dependent_dijkstra, \"astar\": time_dependent_astar}\n",
    "    \"\"\"\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    for algo_name, algo_fn in algorithms.items():\n",
    "        algo_output_dir = os.path.join(output_root, f\"results_{algo_name}\")\n",
    "        os.makedirs(algo_output_dir, exist_ok=True)\n",
    "\n",
    "        print(f\"\\n=== Running algorithm: {algo_name.upper()} ===\")\n",
    "        for split_name, split_dir in base_dirs.items():\n",
    "            print(f\"\\n--- Split: {split_name.upper()} ---\")\n",
    "            df = run_on_dataset(split_name, split_dir, routing_fn=algo_fn)\n",
    "\n",
    "            output_path = os.path.join(algo_output_dir, f\"{split_name}.csv\")\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved {split_name} results to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "89b0f109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running algorithm: DIJKSTRA ===\n",
      "\n",
      "--- Split: TRAIN ---\n",
      "\n",
      "Running time_dependent_dijkstra on TRAIN set\n",
      "Found 4 graphs in /home/floor/projects/FINAL/thesis_ambulance_optimization/data/training_data/network_0\n",
      "Saved train results to evaluation_results/results_dijkstra/train.csv\n",
      "\n",
      "=== Running algorithm: ASTAR ===\n",
      "\n",
      "--- Split: TRAIN ---\n",
      "\n",
      "Running time_dependent_a_star on TRAIN set\n",
      "Found 4 graphs in /home/floor/projects/FINAL/thesis_ambulance_optimization/data/training_data/network_0\n",
      "Start node: 51\n",
      "End node: 15\n",
      "[FOUND] cost=200.515, path=[51, 73, 64, 59, 49, 40, 30, 38, 16, 14, 15]\n",
      "Start node: 29\n",
      "End node: 15\n",
      "[FOUND] cost=186.441, path=[29, 28, 22, 17, 19, 20, 30, 38, 16, 14, 15]\n",
      "Start node: 137\n",
      "End node: 167\n",
      "[FOUND] cost=71.614, path=[137, 143, 157, 150, 167]\n",
      "Start node: 107\n",
      "End node: 47\n",
      "[FOUND] cost=244.224, path=[107, 105, 103, 51, 73, 64, 59, 49, 40, 56, 65, 47]\n",
      "Saved train results to evaluation_results/results_astar/train.csv\n"
     ]
    }
   ],
   "source": [
    "base_dirs = {\n",
    "    \"train\": \"/home/floor/projects/FINAL/thesis_ambulance_optimization/data/training_data\",\n",
    "    # \"val\": \"val_data\",\n",
    "    # \"test\": \"test_data\"\n",
    "}\n",
    "\n",
    "algorithms = {\n",
    "    \"dijkstra\": time_dependent_dijkstra,\n",
    "    \"astar\": time_dependent_a_star\n",
    "}\n",
    "\n",
    "run_all_evaluations(base_dirs, output_root=\"evaluation_results\", algorithms=algorithms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
